DATA_DIR: "/home/main/ssl-optimal-transport/data"
EXP_ID: "mae_cifar10_gw_supervision"
TASK: "mae_pretrain"
DEBUG: 0
DEBUG_THEME: "white"
SEED: 317
OUTPUT_DIR: "/home/main/ssl-optimal-transport/runs/pretrain"
LOG_DIR: ""
EXPERIMENT_NAME: ""
GPUS: [0]
WORKERS: 0
PRINT_FREQ: 0
PIN_MEMORY: true
RANK: 0
SAVE_RESULTS: true

CUDNN:
    BENCHMARK: true

MODEL:
    INIT_WEIGHTS: false
    PRETRAINED: ""
    NAME: "vit_tiny"
    HEADS: ["mae_decode"]
    INPUT_H: 32
    INPUT_W: 32
    MAE_EMBED_DIM: 192
    MAE_PATCH_SIZE: 2
    MAE_ENCODER_DEPTH: 12
    MAE_ENCODER_NUM_HEADS: 3
    MAE_DECODER_DEPTH: 4
    MAE_DECODER_NUM_HEADS: 3
    MAE_MASK_RATIO: 0.75
    SUPERVISION: "/home/main/ssl-optimal-transport/experiments/pretrain/gw_supervision/simclr_cifar10.yaml"

LOSS:
    METRIC: ["mae_mse", "gromov_wasserstein"]

DATASET:
    DATASET: "CIFAR10"
    SAMPLE: "MAE"
    TRAIN_SET: "train"
    TEST_SET: "valid"
    IMAGE_SIZE: 32
    NUM_CLASSES: 10
    MEAN: [0.5]
    STD: [0.5]

TRAIN:
    OPTIMIZER: "adamw"
    DISTRIBUTE: false
    LOCAL_RANK: 0
    HIDE_DATA_TIME: false
    SAVE_ALL_MODEL: true
    RESUME: false
    EPOCHS: 2000
    NUM_ITERS: -1
    LR: 1.5e-4
    WD: 0.05
    BATCH_SIZE: 512
    WARMUP_EPOCHS: 200
    SAVE_INTERVAL: 100
    CHECKPOINT: ""
    SHUFFLE: true
    VAL_INTERVALS: 100
    TRAINVAL: false

TEST:
    BATCH_SIZE: 16
    TASK: "mae_pretrain"
    MODEL_PATH: "/home/main/ssl-optimal-transport/runs/pretrain/mae_cifar10_mse/model_last.pth"
